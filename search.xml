<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[effective-java 第三章：对于所有对象都通用的方法]]></title>
    <url>%2F2018%2F11%2F14%2Feffective-java%2F3%2F</url>
    <content type="text"></content>
      <tags>
        <tag>Effective Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[effective-java 第二章：创建和销毁对象]]></title>
    <url>%2F2018%2F11%2F14%2Feffective-java%2F2%2F</url>
    <content type="text"><![CDATA[使用静态工厂方法代替构造器好处： 静态工厂有名字。静态工厂的名字可以更清晰的描述返回的对象，比较构造器参数例如:BigInteger.probablePrime(int bitLength,Random rnd)返回一个素数需要多个构造器返回多个类型时，只能靠参数识别，开发人员难以记住。而静态工厂方法靠函数名就知道返回的大概内容了。 静态工厂方法不必每次调用都创建一个新对象。可以重复利用对象，免去创建多个相同对象的资源消耗（内存和时间）。可以保证单例。可使不可变类不存在两个相同的实例，使当且仅当 a==b 才存在 a.equals(b) == true ，例如，两个 String 必须要指向同一个，他们才能内容相同。这样做能使用 == 代替 equals() ,直接通过 HashCode 来判断是否相同，提高性能。枚举类（enum）就是这么做的。 静态工厂方法可以返回任意子类型的对象。API 可以返回对象，同时又不会使对象的类变为公有的。这种方式可以隐藏实现类。例如 Java 的集合类（Collections）。客户端通过接口来使用实现类，可以隐藏具体的实现类，API 变更时用户不受任何影响。 创建对象时代码可以更简洁。 缺点： 类如果不含公有的或者受保护的构造器，就不能子类化。 与其他静态方法没任何区别，在 API 文档中查找比较困难。 遇到多个构造器参数时要考虑使用构建器反模式Antipattern 层叠构造器缺点：参数多时难以编写和阅读 setter() 方法设置参数麻烦，而且暴露了 setter() 参数不安全。 解决方法 Builder 模式不直接生成对象，而是利用所有提供的参数来调用对应的静态工厂，得到一个 builder 对象，然后调用对象的 setter 来设置参数。 实现：调用： 不足： 创建对象必须先创建它的构建起，需要一定的开销。 代码多。 总结：如果类的构造器或静态工厂具有多个参数时（4个以上），设计这种类使用 Builder 模式更好，它比重叠构造器更易于阅读编写，比 setter 更安全。 使用私有构造器或枚举类型强化 Singleton 属性公有静态成员是个 final 域123456// Singleton with public final fieldpublic class Elvis &#123; public static final Elvis INSTANCE = new Elvis(); private Elvis()&#123;...&#125; public void leaveTheBuilding()&#123;...&#125;&#125; INSTANCE 实例全局唯一，但通过反射机制仍可调用私有构造函数生成新实例。 公有成员是静态工厂方法（类似于设计模式 —— 单例模式）1234567// Singleton with static factorypublic class Elvis &#123; private static final Elvis INSTANCE = new Elvis(); private Elvis()&#123;...&#125; public static Elvis getInstance() &#123; return INSTANCE; &#125; public void leaveTheBuilding()&#123;...&#125;&#125; 该方法提供了灵活性，可以在不改变 API 的情况下，控制是否单例。第二个是可以返回到一个泛型。但在序列化和反序列化时会存在一些问题。 编写一个包含单个元素的枚举类（最佳实现）12345// Enum singleton - the preferred approachpublic enum Elvis &#123; INSTANCE; public void leaveTheBuilding()&#123;...&#125;&#125; 该方法和 final 域相似，但是自带了序列化，绝对防止多次实例化，即便是反序列或者使用发射机制攻击。 对工具类设置私有构造函数避免创建不必要的对象如使用 String s = “aaa”; 代替 String s = new String(“aaa”);，后者每次都会生成一个新实例。 消除过期对象引用过期对象引用会导致内存泄漏。 三个常见的内存泄漏 类管理自己的内存 缓存 监听器和其他回调 详细内容（书本引用 21页-23页）： 避免使用终结方法（finalizer）java 规范不保证终结方法的及时运行，甚至不保证它的运行。可能程序结束时还有终结方法未执行。 终结方法影响性能，使用终结方法创建和销毁对象大概慢了430倍（作者的测试）。 对于一些资源的释放，最好显式的释放 原文引用（感觉无法归纳，orz）]]></content>
      <tags>
        <tag>Effective Java</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F08%2F18%2F%E5%88%86%E5%B8%83%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[弱一致性（最终一致性）：修改不是即时生效，但是一定的时间后一定是一致的。 强一致性：实时的一致性。 解决算法 主从同步：master 接受写请求，然后复制到所有从服务器，直到全部返回成功。 缺点：低可用性，任何一个节点阻塞，该次写入就出错。 多数派：每次写入和读取都大于 N/2 节点 缺点：读写并发时，不能保证每次都能拿到最新的值。（读写顺序不确定） Paxos（存在多种） | 角色 | 职责 | | –: | :– | | Client | 系统外部角色，发起请求——群众 | | Propser | 接受请求，向集群提出提议。并在冲突时，起到冲突调节的作用——人大代表 | | Accpetor（Voter） | 提议投票和接收者，只有形成法定人数（一般为大多数）时，提议才会被接受——人大代表投票 | | Learner | 提议接受者，backup，备份，对集群一致性没影响——书记官 |]]></content>
  </entry>
  <entry>
    <title><![CDATA[maven 知识积累]]></title>
    <url>%2F2018%2F08%2F18%2Fmaven-%E7%9F%A5%E8%AF%86%E7%A7%AF%E7%B4%AF%2F</url>
    <content type="text"><![CDATA[基本命令 创建 maven 的普通 java 项目： mvn archetype:create -DgroupId=packageName -DartifactId=projectName 创建 maven 的 web 项目： mvn archetype:create -DgroupId=packageName -DactifactId=webappName -DarchtypeArtifactId=maven-archetype-webapp 常用命令 命令 含义 mvn compile 编译源码 mvn test-compile 编译测试源码 mvn test 运行测试 mvn package 打包项目，在 target 下生成已经压缩的包 mvn jar:jar 打包成 jar 包 mvn install 安装源码到本地仓库 mvn deply 部署到私服仓库，上传部署构建，会把target目录下的文件上传，包括源码 常用参数 参数 含义 -x debug 模式 -Dmaven.test.skip=true 跳过运行单元测试]]></content>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbox]]></title>
    <url>%2F2018%2F08%2F18%2Fdubbox%2F</url>
    <content type="text"><![CDATA[一个分布式的远程调用框架 由 阿里 dobbo 改进而来，当当维护 应用场景：大型的 web 项目中，多模块之间的远程调用（ RPC ——调用方知道并拥有接口，但实现 在服务端）。 概念分布式架构。提供高性能和透明化的 RPC 远程服务调用方案，以及 SOA ——面向服务服务架构的解决方案。 特点 远程通讯: 提供对多种基于长连接的NIO框架抽象封装，包括多种线程模型，序列化，以及“请求-响应”模式的信息交换方式。 集群容错: 提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。 自动发现: 基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。 构件： 注册中心（Registry） 服务提供方 (Provider) 服务消费方 (comsumer) 监控中心 （Monitor） 服务运行容器 （Container） 运行： 服务日期负责启动，加载，运行服务提供方 提供方向注册中心注册自己提供的服务 消费者启动时，向注册中心订阅自己所需的服务 注册中心返回地址列表给消费者。如果有变动，注册中心使用长连接推送新数据（http:keep-alive） 消费者从地址列表中，基于软负载均衡算法，选择一台提供者进行调用。如果失败，再选一台调用。 消费者和提供者，在内存中累计调用次数和时间，每分钟定时发送一次统计数据到监控中心。 ###注册中心————Zookeeper （官方推荐，hadoop 组件） ##备注：当当并没有上传 dobbox 代码到 maven 仓库中，所以不能直接在 maven 中引用，可以使用 jar 包，或者 maven install 到本地仓库]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>dubbox</tag>
        <tag>SOA</tag>
        <tag>分布式</tag>
        <tag>RPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建简单的 Scripy 项目]]></title>
    <url>%2F2018%2F07%2F06%2Fscrapy-tutorial-1%2F</url>
    <content type="text"><![CDATA[在爬虫项目的根目录中输入如下命令： 创建项目 1scrapy startproject demoName 创建一个名为 demoName 的 文件夹.该文件夹即为 scrapy 项目的根目录,文件夹中包含以下文件： scrapy.cfg: 项目的配置文件tutorial/: 该项目的python模块。之后您将在此加入代码。tutorial/items.py: 项目中的item文件.tutorial/pipelines.py: 项目中的pipelines文件.tutorial/settings.py: 项目的设置文件.tutorial/spiders/: 放置spider代码的目录. 定义数据项 Item Item 即爬取到的单个网页的数据容器，如果把数据保存到数据库的话， Item 即为数据库的行。创建一个 Item 类必须继承 scrapy.item实例:123456import scrapyclass TestItem(scrapy.Item): title = scrapy.Field() link = scrapy.Field() desc = scrapy.Field() 3. 编写爬虫在一个 scrapy 项目中可以包括多个爬虫，但是默认配置下只能运行一个。如果想启动多个爬虫请参考 —— Scrapy之“并行”爬虫创建 scrapy 爬虫必须继承 scrapy.Spider 类，且定义以下三个属性： - name : 爬虫的 唯一标识 ,启动爬虫时就必须传递该参数 - start_urls : 包含了Spider启动时爬取的 url 列表。因此，第一个被爬取到的页面将是其中之一。后续的 URL 将从初始页面的数据中提取。 - parse() : spider 的一个方法。被调用时，每个初始 URL 完成下载后生成的 Response 对象将会作为唯一的参数传递给该函数。。该方法负责解析返回的数据（response data），提前数据——生成 Item 以及生成进一步处理的 URL 的 Request 对象。示例：1234567891011121314import scrapyclass TestSpider(scrapy.Spider): name = &quot;test&quot; allowed_domains = [&quot;w3school.com.cn&quot;] start_urls = [ &quot;http://www.w3school.com.cn/html/index.asp&quot;, &quot;http://www.w3school.com.cn/js/index.asp&quot; ] def parse(self, response): filename = response.url.split(&quot;/&quot;)[-2] with open(filename, &apos;wb&apos;) as f: f.write(response.body) 4. 启动爬虫 1scrapy crawl test 运行该命令时，scrapy 将会为 start_url 中的每个 URL 创建一个 scrapy.Request 对象，并将执行生成的 scrapy.http.Response 作为参数传递给 parse() 方法处理。 虽然 scrapy 启动时会创建十个进程，但是只有一个线程会用于下载网页内容，其他内容都是作 dns 解析之类的工作。那么如何实现 scrapy 的并发呢，有两个方法： 创建 docker 容器，运行多个容器来实现并发，可以通过 redis 来控制请求 url 防止重复请求。 设置 settings.DOWNOAD_DELAY=0 该参数控制网页下载的间隔（单位秒），设置为零可以实现伪并发，但可能会被反爬，但是即便如此设置理论上仍旧只能使用一个 cpu 核心。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>scrapy</tag>
        <tag>spider</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F07%2F06%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
